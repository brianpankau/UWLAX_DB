{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 1(a).  Reading Amazon Reviews.\n",
    "\n",
    "In this problem, we will analyze Amazon reviews to determine what characteristics make them most helpful.\n",
    "\n",
    "Download the file of Amazon gourmet food reviews from the [Stanford Large Network Dataset Collection](https://snap.stanford.edu/data/web-FineFoods.html).   (Your computer may already have a utility installed that can unzip the archive as a text file; if not, [7-zip](http://www.7-zip.org/) is a useful utility for Windows. You can also use an online utility by doing a web search for: ``open .gz files online``.)\n",
    "\n",
    "Create a pandas DataFrame object with the following entries for each review:\n",
    "\n",
    "* Product ID\n",
    "* Number of people who voted this review helpful\n",
    "* Total number of people who rated this review\n",
    "* Rating of the product\n",
    "* Text of the review\n",
    "\n",
    "For the second and third of these, the information will be given in the file as ```1/5```, which would correspond to 1 vote for helpful out of 5 people who rated the review.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ProductId', 'UserId', 'Name', 'Helpfullness', 'Score', 'Time',\n",
      "       'Summary', 'Text', 'Voted_helpful', 'Voted_total'],\n",
      "      dtype='object')\n",
      "ProductId        object\n",
      "UserId           object\n",
      "Name             object\n",
      "Helpfullness     object\n",
      "Score            object\n",
      "Time             object\n",
      "Summary          object\n",
      "Text             object\n",
      "Voted_helpful     int64\n",
      "Voted_total       int64\n",
      "dtype: object\n",
      "568454\n",
      "       Voted_helpful   Voted_total\n",
      "count  568454.000000  568454.00000\n",
      "mean        1.743817       2.22881\n",
      "std         7.636513       8.28974\n",
      "min         0.000000       0.00000\n",
      "25%         0.000000       0.00000\n",
      "50%         0.000000       1.00000\n",
      "75%         2.000000       2.00000\n",
      "max       866.000000     923.00000\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Author: Brian Pankau\n",
    "# Class: DS710 Summer 2017\n",
    "# Assignment: Python 11\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------    \n",
    "# Problem 1(a)\n",
    "# Create a pandas DataFrame object with the following entries for each review:\n",
    "# •Product ID\n",
    "# •Number of people who voted this review helpful\n",
    "# •Total number of people who rated this review\n",
    "# •Rating of the product\n",
    "# •Text of the review\n",
    "\n",
    "# For the second and third of these, \n",
    "# the information will be given in the file as 1/5, \n",
    "# which would correspond to 1 vote for helpful out of 5 people who rated the review.\n",
    "\n",
    "\n",
    "# Description: Read foods.txt input file and creates a table in foods_out.txt\n",
    "#   that represents the input data as a tab delimited table that will be used\n",
    "#   to create a data frame df.\n",
    "#   The intermediate file foods_parsed.txt is generated in order to handle\n",
    "#   embedded carriage returns within each field with each text block.\n",
    "\n",
    "# Control Flow:\n",
    "# convert unknown encoding into ascii => parse_input_fn -> parse_output_fn\n",
    "# parse input file an replace any embeddeed CR with a space => parse_input_fn -> parse_output_fn\n",
    "# construct a list of lists from the fields within each text block => process_input_fn -> list_of_lists\n",
    "# write the table header to the output file => header -> process_output_fn\n",
    "# process the list_of_lists, extract values from key:value pairs, generate each row of the output table => list_of_lists -> key:value -> value -> process_output_fn\n",
    "# create dataframe from table in file\n",
    "\n",
    "\n",
    "# set debug status, 0=OFF, 1=ON\n",
    "debug = 0\n",
    "\n",
    "# import libraries\n",
    "import string\n",
    "import codecs\n",
    "import sys\n",
    "import binascii\n",
    "import unicodedata\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "\n",
    "# set file names\n",
    "if (debug) :\n",
    "    # 100 input text blocks\n",
    "    parse_input_fn0    = \"foods100.txt\"\n",
    "    parse_output_fn0   = \"foods100_parsed_0.txt\"\n",
    "    parse_input_fn1    = \"foods100_parsed_0.txt\"\n",
    "    parse_output_fn1   = \"foods100_parsed.txt\"\n",
    "    process_input_fn   = \"foods100_parsed.txt\"\n",
    "    process_output_fn  = \"foods100_out.txt\"\n",
    "    process_output_csv  = \"foods100.csv\"\n",
    "else :\n",
    "    # Actual data file for run-for-record\n",
    "   parse_input_fn0    = \"foods.txt\"\n",
    "   parse_output_fn0   = \"foods_parsed_0.txt\"\n",
    "   parse_input_fn1    = \"foods_parsed_0.txt\"\n",
    "   parse_output_fn1   = \"foods_parsed.txt\"\n",
    "   process_input_fn   = \"foods_parsed.txt\"\n",
    "   process_output_fn  = \"foods_out.txt\"\n",
    "   process_output_csv  = \"foods.csv\"\n",
    "\n",
    "    \n",
    "# set working directory\n",
    "os.chdir('C:\\_DS710\\Temp11')\n",
    "\n",
    "\n",
    "# convert unknown encoding into ascii, remove non-printable characters, multiple spaces\n",
    "f2 = open(parse_output_fn0, 'w', encoding='utf-8', errors=\"ignore\")\n",
    "with open(parse_input_fn0, 'r', encoding=\"utf-8\", errors=\"ignore\") as f1:\n",
    "    for aline in iter(f1.readline, \"\"):\n",
    "        # replace all multiple spaces with a single space\n",
    "        aline_str = aline.replace(chr(9), chr(20))\n",
    "        aline_str1 = aline_str.replace(\"  \", chr(20))\n",
    "        aline_str2 = aline_str1.replace(chr(34), chr(39))\n",
    "        #strip special characters from salaries\n",
    "        printable = set(string.printable)\n",
    "        aline_str3 = '' .join(filter(lambda x: x in string.printable, aline_str2))\n",
    "        # write the processed line to a file\n",
    "        f2.write(aline_str3)\n",
    "f2.close()\n",
    "f1.close()\n",
    "\n",
    "\n",
    "# parse input file an replace any embeddeed CR with a space\n",
    "f_out_parse = open(parse_output_fn1, 'w', encoding='utf-8', errors=\"surrogateescape\")\n",
    "with open(parse_input_fn1, \"r\", encoding='utf-8', errors=\"surrogateescape\") as f_in_parse:\n",
    "    # process each field in the input text block\n",
    "    for parse_line in f_in_parse :\n",
    "        # input line is only a CR, issue CR to terminate text block\n",
    "        if ((len(parse_line) == 1) & (parse_line[0:1] == \"\\n\")):\n",
    "            f_out_parse.write(\"\\n\")\n",
    "        # input line is a product field of text block\n",
    "        elif (parse_line[0:8] == \"product/\") :\n",
    "            f_out_parse.write(\"\\n\")\n",
    "            f_out_parse.write(parse_line[0:len(parse_line)-1])\n",
    "        # input line is a review field of text block\n",
    "        elif (parse_line[0:7] == \"review/\") :\n",
    "            f_out_parse.write(\"\\n\")\n",
    "            f_out_parse.write(parse_line[0:len(parse_line)-1])\n",
    "        # input line represents a continuation of the previous input field\n",
    "        else :\n",
    "            f_out_parse.write(parse_line[0:len(parse_line)-1])\n",
    "f_out_parse.write(\"\\n\\n\")\n",
    "f_out_parse.close()\n",
    "\n",
    "# construct a list of lists from the fields within each text block\n",
    "list_of_lists = []\n",
    "with open(process_input_fn, \"r\", encoding='utf-8', errors=\"ignore\") as f_in:\n",
    "    # read the blank line at the beginning of the parsed file that was generated\n",
    "    empty_line = f_in.readline()\n",
    "    if (debug) :\n",
    "        print(\"EMPTY LINE\", empty_line)\n",
    "\n",
    "    linecount = 1\n",
    "    line_list = []\n",
    "    for line in f_in:\n",
    "        if (debug) :\n",
    "            print(\"****\", linecount, line)\n",
    "\n",
    "        if (linecount % 9 != 0):\n",
    "            if (debug) :\n",
    "                print(linecount, \"IF BEFORE\", line_list)\n",
    "            line_list.append(line)\n",
    "            if (debug) :\n",
    "                print(linecount, \"IF AFTER\", line_list)\n",
    "            linecount = linecount + 1\n",
    "        else:\n",
    "            if (debug) :\n",
    "                print(linecount, \"ELSE BEFORE\", line_list)\n",
    "\n",
    "            list_of_lists.append(line_list)\n",
    "\n",
    "            if (debug) :\n",
    "                print(linecount, \"ELSE AFTER\", line_list)\n",
    "\n",
    "            line_list = []\n",
    "            linecount = 1\n",
    "\n",
    "# define search strings\n",
    "key_0 = \"product/productId: \"\n",
    "key_1 = \"review/userId: \"\n",
    "key_2 = \"review/profileName: \"\n",
    "key_3 = \"review/helpfulness: \"\n",
    "key_4 = \"review/score: \"\n",
    "key_5 = \"review/time: \"\n",
    "key_6 = \"review/summary: \"\n",
    "key_7 = \"review/text: \"\n",
    "\n",
    "# define labels for output header\n",
    "label_rowid = \"Rowid\"\n",
    "label_0 = \"ProductId\"\n",
    "label_1 = \"UserId\"\n",
    "label_2 = \"Name\"\n",
    "label_3 = \"Helpfulness\"\n",
    "label_4 = \"Score\"\n",
    "label_5 = \"Time\"\n",
    "label_6 = \"Summary\"\n",
    "label_7 = \"Text\"\n",
    "\n",
    "label_0_len = \"ProductId_len\"\n",
    "label_1_len = \"UserId_len\"\n",
    "label_2_len = \"Name_len\"\n",
    "label_3_len = \"Helpfulness_len\"\n",
    "label_4_len = \"Score_len\"\n",
    "label_5_len = \"Time_len\"\n",
    "label_6_len = \"Summary_len\"\n",
    "label_7_len = \"Text_len\"\n",
    "\n",
    "head_str = chr(34)\n",
    "mid_str = chr(34) + chr(9) + chr(34)\n",
    "tail_str = chr(34) + chr(10)\n",
    "\n",
    "# open the output file\n",
    "f_out = open(process_output_fn, 'w', encoding='utf-8', errors=\"ignore\")\n",
    "\n",
    "# write the table header to the output file\n",
    "if (debug) :\n",
    "    header_str = head_str + label_rowid + mid_str + label_0 + mid_str + label_1 + mid_str + label_2 + mid_str + label_3 + mid_str + label_4 + mid_str + label_5 + mid_str + label_6 + mid_str + label_7 + tail_str\n",
    "else :\n",
    "    header_str = head_str + label_0 + mid_str + label_1 + mid_str + label_2 + mid_str + label_3 + mid_str + label_4 + mid_str + label_5 + mid_str + label_6 + mid_str + label_7 + tail_str\n",
    "#    header_str = head_str + \\\n",
    "#        label_rowid + mid_str + \\\n",
    "#        label_0 + mid_str + label_0_len + mid_str + \\\n",
    "#        label_1 + mid_str + label_1_len + mid_str + \\\n",
    "#        label_2 + mid_str + label_2_len + mid_str + \\\n",
    "#        label_3 + mid_str + label_3_len + mid_str + \\\n",
    "#        label_4 + mid_str + label_4_len + mid_str + \\\n",
    "#        label_5 + mid_str + label_5_len + mid_str + \\\n",
    "#        label_6 + mid_str + label_6_len + mid_str + \\\n",
    "#        label_7 + mid_str + label_7_len + tail_str\n",
    "\n",
    "# ouput the table header\n",
    "f_out.write(header_str)\n",
    "\n",
    "# process the list_of_lists, extract values from key:value pairs, generate each row of the output table\n",
    "rowid = 1\n",
    "for a_list in list_of_lists :\n",
    "    if (debug) :\n",
    "        f_out.write(str(len(list_of_lists)))\n",
    "        f_out.write(\"\\n\")\n",
    "\n",
    "    if (debug) :\n",
    "        f_out.write(str(len(a_list)))\n",
    "        f_out.write(\"\\n\")\n",
    "\n",
    "    # extract the value from the key : value pair and remove the trailing CR\n",
    "    value_0 = a_list[0][len(key_0) : len(a_list[0]) - 1]\n",
    "    value_1 = a_list[1][len(key_1) : len(a_list[1]) - 1]\n",
    "    value_2 = a_list[2][len(key_2) : len(a_list[2]) - 1]\n",
    "    value_3 = a_list[3][len(key_3) : len(a_list[3]) - 1]\n",
    "    value_4 = a_list[4][len(key_4) : len(a_list[4]) - 1]\n",
    "    value_5 = a_list[5][len(key_5) : len(a_list[5]) - 1]\n",
    "    value_6 = a_list[6][len(key_6) : len(a_list[6]) - 1]\n",
    "    value_7 = a_list[7][len(key_7) : len(a_list[7]) - 1]\n",
    "\n",
    "    if (debug) :\n",
    "        output_str = head_str + \\\n",
    "            str(rowid) + mid_str + \\\n",
    "            value_0 + mid_str + \\\n",
    "            value_1 + mid_str + \\\n",
    "            value_2 + mid_str + \\\n",
    "            value_3 + mid_str + \\\n",
    "            value_4 + mid_str + \\\n",
    "            value_5 + mid_str + \\\n",
    "            value_6 + mid_str + \\\n",
    "            value_7 + tail_str\n",
    "    else :\n",
    "        output_str = head_str + value_0 + mid_str + value_1 + mid_str + \\\n",
    "            value_2 + mid_str + value_3 + mid_str + value_4 + mid_str + \\\n",
    "            value_5 + mid_str + value_6 + mid_str + value_7 + tail_str\n",
    "#        output_str = head_str + \\\n",
    "#            str(rowid) + mid_str + \\\n",
    "#            value_0 + mid_str + str(len(value_0)) + mid_str + \\\n",
    "#            value_1 + mid_str + str(len(value_1)) + mid_str + \\\n",
    "#            value_2 + mid_str + str(len(value_2)) + mid_str + \\\n",
    "#            value_3 + mid_str + str(len(value_3)) + mid_str + \\\n",
    "#            value_4 + mid_str + str(len(value_4)) + mid_str + \\\n",
    "#            value_5 + mid_str + str(len(value_5)) + mid_str + \\\n",
    "#            value_6 + mid_str + str(len(value_6)) + mid_str + \\\n",
    "#            value_7 + mid_str + str(len(value_7)) + tail_str\n",
    "\n",
    "    # write the row to the table\n",
    "    f_out.write(output_str)\n",
    "    rowid = rowid + 1\n",
    "\n",
    "    # close the file containing the table\n",
    "f_out.close()\n",
    "\n",
    "# create dataframe from table in file for further proocessing\n",
    "if (debug == 1) :\n",
    "    # create a temp df to remove quotechars & set column names\n",
    "    df = pd.read_table(process_output_fn, sep='\\t', encoding='utf-8', quotechar='\"', lineterminator=\"\\n\", na_values='NaN', \\\n",
    "        names=['ProductId', 'UserId', 'Name', 'Helpfullness', 'Score', 'Time', 'Summary', 'Text','Help_tuple'],            \\\n",
    "        dtype={'ProductId':str,'UserId':str,'Name':str,'Helpfullness':str,'Score':str,'Time':str,'Summary':str,'Text':str,'Help_tuple':str})\n",
    "    # debug df\n",
    "    print(df_tmp)\n",
    "    print(df_tmp.describe())\n",
    "else:\n",
    "    # create a temp df to remove quotechars & set column names\n",
    "    df = pd.read_table(process_output_fn, sep='\\t', encoding='utf-8', quotechar='\"', lineterminator=\"\\n\", na_values='NaN', header=0, \\\n",
    "        names=['ProductId', 'UserId', 'Name', 'Helpfullness', 'Score', 'Time', 'Summary', 'Text'],            \\\n",
    "        dtype={'ProductId':str,'UserId':str,'Name':str,'Helpfullness':str,'Score':str,'Time':str,'Summary':str,'Text':str})\n",
    "\n",
    "# convert Helpfullness ratio into integers: calculate number of people who voted helpfull & Total number of people who voted\n",
    "# - convert ratio string into a 3-part tuple string\n",
    "# - extract the nominator and denominator & convert to an integer\n",
    "# - insert converted strings into 2 new columns in dataframe\n",
    "z = lambda a: a.partition(\"/\")\n",
    "h_series = Series(df.Helpfullness)\n",
    "h_tuple = h_series.apply(z)\n",
    "y = lambda b: int(b[0])\n",
    "x = lambda c: int(c[2])\n",
    "h_num_int = Series(h_tuple.apply(y))\n",
    "h_denum_int = Series(h_tuple.apply(x))\n",
    "df['Voted_helpful'] = h_num_int\n",
    "df['Voted_total'] = h_denum_int\n",
    "\n",
    "# generate results\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "print(df.ProductId.count())\n",
    "print(df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 1(b).  Analyzing review text.\n",
    "\n",
    "Add columns to your DataFrame for the length of a review, the number of exclamation points in a review, and the fraction of people who rated a review helpful. You should calculate the fraction who rated a review helpful using the two columns you made in 1a, and a ratio of 1 helpful rating out of 5 total ratings should be entered as 0.2, not the string ```1/5```. If no people voted on whether a problem was helpful, the corresponding entry in your percentage helpful column should be ```NaN```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Voted_helpful   Voted_total  Review_length  Exclamation_count  \\\n",
      "count  568454.000000  568454.00000  568454.000000      568454.000000   \n",
      "mean        1.743817       2.22881     432.734969           0.758047   \n",
      "std         7.636513       8.28974     442.738999           1.564842   \n",
      "min         0.000000       0.00000      12.000000           0.000000   \n",
      "25%         0.000000       0.00000     178.000000           0.000000   \n",
      "50%         0.000000       1.00000     299.000000           0.000000   \n",
      "75%         2.000000       2.00000     523.000000           1.000000   \n",
      "max       866.000000     923.00000   21221.000000          84.000000   \n",
      "\n",
      "       Percentage_helpful  \n",
      "count       298402.000000  \n",
      "mean             0.776975  \n",
      "std              0.346321  \n",
      "min              0.000000  \n",
      "25%              0.600000  \n",
      "50%              1.000000  \n",
      "75%              1.000000  \n",
      "max              3.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------------------------------    \n",
    "# Problem 1b    \n",
    "# Add columns to your DataFrame for \n",
    "# the length of a review, \n",
    "# the number of exclamation points in a review, and \n",
    "# the fraction of people who rated a review helpful. \n",
    "#\n",
    "# You should calculate the fraction who rated a review helpful using the two columns you made in 1a, and \n",
    "# a ratio of 1 helpful rating out of 5 total ratings should be entered as 0.2, not the string 1/5. \n",
    "# If no people voted on whether a problem was helpful, the corresponding entry in your percentage helpful column should be NaN.\n",
    "\n",
    "# the length of a review Text string\n",
    "w = lambda d: len(d)\n",
    "text_series = Series(df.Text)\n",
    "review_len = text_series.apply(w)\n",
    "df['Review_length'] = review_len\n",
    "\n",
    "# count the number of exclamation points in a review\n",
    "v = lambda e: e.count(\"!\")\n",
    "exclamation_cnt = text_series.apply(v)\n",
    "df['Exclamation_count'] = exclamation_cnt\n",
    "\n",
    "# the fraction of people who rated a review helpful\n",
    "fraction_series = np.where(df.Voted_total == 0, np.nan, df.Voted_helpful / df.Voted_total)\n",
    "df['Percentage_helpful'] = fraction_series\n",
    "\n",
    "# print results\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 1(c).  Summary statistics.\n",
    "\n",
    "How many reviews are in the data set?  What is the average length of a review (in characters)?  What is the average rating?  What is the greatest number of exclamation marks used in a single review?  Use the pandas package to answer these questions, then summarize your results in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many reviews are in the data set? => 568454\n",
      "What is the average length of a review (in characters)? => 432.7349688805075\n",
      "What is the average rating?  => 1.7438174416927315\n",
      "What is the greatest number of exclamation marks used in a single review? => 84\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------------------------------    \n",
    "# Problem 1(c). Summary statistics.\n",
    "# How many reviews are in the data set? \n",
    "# What is the average length of a review (in characters)? \n",
    "# What is the average rating? \n",
    "# What is the greatest number of exclamation marks used in a single review? \n",
    "# Use the pandas package to answer these questions, then summarize your results in a markdown cell.\n",
    "\n",
    "print(\"How many reviews are in the data set? =>\", df.shape[0])\n",
    "print(\"What is the average length of a review (in characters)? =>\", df.Review_length.mean())\n",
    "print(\"What is the average rating?  =>\", df.Voted_helpful.mean())\n",
    "print(\"What is the greatest number of exclamation marks used in a single review? =>\", df.Exclamation_count.max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many reviews are in the data set? => 568454\n",
    "What is the average length of a review (in characters)? => 432.7349688805075\n",
    "What is the average rating?  => 1.7438174416927315\n",
    "What is the greatest number of exclamation marks used in a single review? => 84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Problem 1(d).  Export.\n",
    "\n",
    "Save your DataFrame as a .csv file suitable for future analysis in R.  Your .csv file should not include the review text column, as the presence of commas and quotation marks will make reading the file difficult.  You should also convert entries from ```NaN``` to the empty string before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------------------------------------------------    \n",
    "#Problem 1(d). Export.\n",
    "# Save your DataFrame as a .csv file suitable for future analysis in R. \n",
    "# Your .csv file should not include the review text column, \n",
    "# as the presence of commas and quotation marks will make reading the file difficult. \n",
    "# You should also convert entries from NaN to the empty string before saving.\n",
    "df.to_csv(process_output_csv, sep=',', encoding='utf-8', quotechar='\"', na_rep='', index=False, index_label=False, \\\n",
    "    columns=['ProductId', 'UserId', 'Name', 'Helpfullness', 'Score', 'Time', \\\n",
    "    'Summary', 'Voted_helpful', 'Voted_total', 'Review_length', \\\n",
    "    'Exclamation_count', 'Percentage_helpful'],\n",
    "    header=['ProductId', 'UserId', 'Name', 'Helpfullness', 'Score', 'Time', \\\n",
    "    'Summary', 'Voted_helpful', 'Voted_total', 'Review_length', \\\n",
    "    'Exclamation_count', 'Percentage_helpful'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
