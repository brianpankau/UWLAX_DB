{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1(a).  Word length.\n",
    "\n",
    "Write a function called ```word_length_list()``` which takes a string and returns a list with the length of each word in the string.  For each word, count the number of English, alphanumeric characters.  Words are defined as text separated by spaces. Your function should ignore punctuation.  For example, ```word_length_list(\"Haven't you eaten 8 oranges today?\")``` should return ```[6,3,5,1,7,5]```.  \n",
    "\n",
    "Call or create other functions as necessary to organize your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input string =  Haven't you eaten 8 oranges today?\n",
      "\n",
      "input string w/o punctuation =  Havent you eaten 8 oranges today\n",
      "\n",
      "input string converted into a list =  ['Havent', 'you', 'eaten', '8', 'oranges', 'today']\n",
      "\n",
      "character count per word in input string w/o punctuation =  [6, 3, 5, 1, 7, 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Author: Brian Pankau\n",
    "# Class: DS710 Summer 2017\n",
    "# Assignment: Python 7\n",
    "\n",
    "\n",
    "# import libraries\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "import binascii\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "# set working directory\n",
    "os.chdir('C:/_DS710/Temp07')\n",
    "\n",
    "# set debug options (1=TRUE)\n",
    "debug = 1\n",
    "\n",
    "# Problem 1a: Word Length\n",
    "# ---------------------------------------------------------------------\n",
    "# Write a function called word_length_list() which takes a string and \n",
    "# returns a list with the length of each word in the string. \n",
    "# For each word, count the number of English, alphanumeric characters. \n",
    "# Words are defined as text separated by spaces. \n",
    "# Your function should ignore punctuation. \n",
    "# For example, word_length_list(\"Haven't you eaten 8 oranges today?\") \n",
    "# should return [6,3,5,1,7,5]. \n",
    "# Call or create other functions as necessary to organize your work.\n",
    "\n",
    "# define a function to remove the standard punctuation marks from a string\n",
    "rmPunctuation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "def rmPunctuation(s):\n",
    "    return s.translate(rmPunctuation_table)\n",
    "\n",
    "# define a function to count the number of characters per word in a word list\n",
    "def word_length_list(s):\n",
    "    # rm punctuation characters\n",
    "    s1 = rmPunctuation(s)\n",
    "    \n",
    "    # convert string into a list by splitting on a whitespace character\n",
    "    list_str = s1.split(\" \")\n",
    "    \n",
    "    if (debug):\n",
    "        print(\"input string converted into a list = \", list_str)\n",
    "        print(\"\")\n",
    "    \n",
    "    # create a list of lengths of the words in the list\n",
    "    char_count_word_list = []\n",
    "    for l in list_str:\n",
    "        char_count_word_list.append(len(l))\n",
    "        \n",
    "    return char_count_word_list\n",
    "\n",
    "\n",
    "# test Problem 1a functions\n",
    "inputStr = \"Haven't you eaten 8 oranges today?\"\n",
    "if (debug):\n",
    "    print(\"input string = \", inputStr)\n",
    "    print(\"\")\n",
    "    print(\"input string w/o punctuation = \", rmPunctuation(inputStr))\n",
    "    print(\"\")\n",
    "    print(\"character count per word in input string w/o punctuation = \", word_length_list(rmPunctuation(inputStr)))\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1(b).  \"A Mourner.\"\n",
    "\n",
    "The text below is an anonymous essay published in The Boston Gazette and Country Journal on January 8, 1770. \n",
    "\n",
    ">The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Father’s House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble Cause--Whose manly Spirit (after this Accident happened) appear’d in his discreet Answers to his Doctor, his Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of bodily Pain; and with which he met the King of Terrors.  These Things, together with the several heroic Pieces found in his Pocket, particularly Wolfe’s Summit of human Glory, gives Reason to think he had a martial Genius, and would have made a clever Man.\n",
    "\t\t\t\t\t\n",
    "> A Mourner.\n",
    "\n",
    "(Source:  Michael Sullivan, _Statistics:  Informed Decisions Using Data_, 4th ed.  p. 188-189.)\n",
    "\n",
    "Use your function ```word_length_list()``` from 1(a) to find the length of each word in \"A Mourner\". (Note that your output should end in . . ., 3, 1, 7].)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input string =  The general Sympathy and Concern for the Murder of the Lad by the base and infamous Richardson on the 22d Instant, will be sufficient Reason for your Notifying the Public that he will be buried from his Father’s House in Frogg Lane, opposite Liberty-Tree, on Monday next, when all the Friends of Liberty may have an Opportunity of paying their last Respects to the Remains of this little Hero and first Martyr to the noble Cause--Whose manly Spirit (after this Accident happened) appear’d in his discreet Answers to his Doctor, his Thanks to the Clergymen who prayed with him, and Parents, and while he underwent the greatest Distress of bodily Pain; and with which he met the King of Terrors. These Things, together with the several heroic Pieces found in his Pocket, particularly Wolfe’s Summit of human Glory, gives Reason to think he had a martial Genius, and would have made a clever Man.\r\n",
      "A Mourner.\n",
      "\n",
      "input string converted into a list =  ['The', 'general', 'Sympathy', 'and', 'Concern', 'for', 'the', 'Murder', 'of', 'the', 'Lad', 'by', 'the', 'base', 'and', 'infamous', 'Richardson', 'on', 'the', '22d', 'Instant', 'will', 'be', 'sufficient', 'Reason', 'for', 'your', 'Notifying', 'the', 'Public', 'that', 'he', 'will', 'be', 'buried', 'from', 'his', 'Father’s', 'House', 'in', 'Frogg', 'Lane', 'opposite', 'LibertyTree', 'on', 'Monday', 'next', 'when', 'all', 'the', 'Friends', 'of', 'Liberty', 'may', 'have', 'an', 'Opportunity', 'of', 'paying', 'their', 'last', 'Respects', 'to', 'the', 'Remains', 'of', 'this', 'little', 'Hero', 'and', 'first', 'Martyr', 'to', 'the', 'noble', 'CauseWhose', 'manly', 'Spirit', 'after', 'this', 'Accident', 'happened', 'appear’d', 'in', 'his', 'discreet', 'Answers', 'to', 'his', 'Doctor', 'his', 'Thanks', 'to', 'the', 'Clergymen', 'who', 'prayed', 'with', 'him', 'and', 'Parents', 'and', 'while', 'he', 'underwent', 'the', 'greatest', 'Distress', 'of', 'bodily', 'Pain', 'and', 'with', 'which', 'he', 'met', 'the', 'King', 'of', 'Terrors', 'These', 'Things', 'together', 'with', 'the', 'several', 'heroic', 'Pieces', 'found', 'in', 'his', 'Pocket', 'particularly', 'Wolfe’s', 'Summit', 'of', 'human', 'Glory', 'gives', 'Reason', 'to', 'think', 'he', 'had', 'a', 'martial', 'Genius', 'and', 'would', 'have', 'made', 'a', 'clever', 'Man', 'A', 'Mourner']\n",
      "\n",
      "caracter count per word in input string =  [3, 7, 8, 3, 7, 3, 3, 6, 2, 3, 3, 2, 3, 4, 3, 8, 10, 2, 3, 3, 7, 4, 2, 10, 6, 3, 4, 9, 3, 6, 4, 2, 4, 2, 6, 4, 3, 8, 5, 2, 5, 4, 8, 11, 2, 6, 4, 4, 3, 3, 7, 2, 7, 3, 4, 2, 11, 2, 6, 5, 4, 8, 2, 3, 7, 2, 4, 6, 4, 3, 5, 6, 2, 3, 5, 10, 5, 6, 5, 4, 8, 8, 8, 2, 3, 8, 7, 2, 3, 6, 3, 6, 2, 3, 9, 3, 6, 4, 3, 3, 7, 3, 5, 2, 9, 3, 8, 8, 2, 6, 4, 3, 4, 5, 2, 3, 3, 4, 2, 7, 5, 6, 8, 4, 3, 7, 6, 6, 5, 2, 3, 6, 12, 7, 6, 2, 5, 5, 5, 6, 2, 5, 2, 3, 1, 7, 6, 3, 5, 4, 4, 1, 6, 3, 1, 7]\n"
     ]
    }
   ],
   "source": [
    "# Problem 1b: A Mourner\n",
    "# ---------------------------------------------------------------------\n",
    "# Use your function word_length_list() from 1(a) to find the length \n",
    "# of each word in \"A Mourner\". (Note that your output should end \n",
    "# in . . ., 3, 1, 7].)\n",
    "\n",
    "\n",
    "# define a function to remove carriage returns from a string\n",
    "def rmCarriageReturns(s):\n",
    "    split_list = s.splitlines()\n",
    "    # if CR were present then reverse the list and exclude ''\n",
    "    if (len(split_list) > 1):\n",
    "        split_list.reverse()\n",
    "        s1 = split_list.pop()\n",
    "        for e in split_list:\n",
    "            if (e != ''):\n",
    "                s1 = s1 + \" \" + e\n",
    "        return s1\n",
    "    else:\n",
    "        s1 = split_list[0]\n",
    "        return s1\n",
    "\n",
    "# test Problem 1b functions\n",
    "inputStr = \"The general Sympathy and Concern for the Murder of the \\\n",
    "Lad by the base and infamous Richardson on the 22d Instant, \\\n",
    "will be sufficient Reason for your Notifying the Public that he will \\\n",
    "be buried from his Father’s House in Frogg Lane, opposite Liberty-Tree, \\\n",
    "on Monday next, when all the Friends of Liberty may have an Opportunity \\\n",
    "of paying their last Respects to the Remains of this little Hero and \\\n",
    "first Martyr to the noble Cause--Whose manly Spirit (after this Accident \\\n",
    "happened) appear’d in his discreet Answers to his Doctor, his Thanks to \\\n",
    "the Clergymen who prayed with him, and Parents, and while he underwent \\\n",
    "the greatest Distress of bodily Pain; and with which he met the King of \\\n",
    "Terrors. These Things, together with the several heroic Pieces found in \\\n",
    "his Pocket, particularly Wolfe’s Summit of human Glory, gives Reason to \\\n",
    "think he had a martial Genius, and would have made a clever Man.\\\n",
    "\\r\\n\\\n",
    "A Mourner.\"\n",
    "\n",
    "if (debug):\n",
    "    print(\"input string = \", inputStr)\n",
    "    print(\"\")\n",
    "    print(\"caracter count per word in input string = \", word_length_list(rmCarriageReturns(inputStr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1(c). _Pride and Prejudice_.\n",
    "\n",
    "Use Python to count the number of words and mean length of words in each sentence of Pride and Prejudice (We have provided a .txt file in the repo, which is available without restrictions from Project Gutenberg).  Save your result as a ```.csv``` file and include it with your submission.\n",
    "\n",
    "* Create new functions as necessary to organize your work.\n",
    "* Include comments to explain the purpose and arguments of each function you create.\n",
    "* Note that the mean length of words in the sample sentence from 1(a) ```\"Haven't you eaten 8 oranges today?\"``` is 4.5.\n",
    "* A sentence ends with a period, exclamation point, or question mark. A hyphen, dash, or apostrophe does not end a sentence. Quotation marks do not end a sentence. But also, some periods do not end sentences. For example, Mrs., Mr., Dr., Fr., Jr., St., are all commonly occurring abbreviations that almost never end sentences, and they occur enough in Pride and Prejudice that you need to deal with them or your averages will be impacted significantly. An ellipsis sometimes ends a sentence and sometimes does not, but for this assignment you may assume an ellipsis ends a sentence (but note it does not end 3 sentences!) \n",
    "* Do *not* use Python packages (like nltk) or code directly copied from online resources (such as regex for splitting text) in order to divide sentences. Write your own code to do this from first principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   totalWordLength  wordCount  meanWordLength  \\\n",
      "0              129         31        4.161290   \n",
      "1              208         47        4.425532   \n",
      "2               78         21        3.714286   \n",
      "3               27          7        3.857143   \n",
      "4               65         19        3.421053   \n",
      "\n",
      "                                   cleanSentenceList  \n",
      "0  [PRIDE, AND, PREJUDICE, By, Jane, Austen, Chap...  \n",
      "1  [However, little, known, the, feelings, or, vi...  \n",
      "2  [My, dear, Mr, Bennet, said, his, lady, to, hi...  \n",
      "3          [Mr, Bennet, replied, that, he, had, not]  \n",
      "4  [But, it, is, returned, she, for, Mrs, Long, h...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Problem 1c: Pride and Prejudice\n",
    "# ---------------------------------------------------------------------\n",
    "# reads input file character by character\n",
    "# input:  a file name\n",
    "# output: a text string that contains the contents of the input file\n",
    "# import libraries\n",
    "\n",
    "# import libraries\n",
    "import string\n",
    "import os\n",
    "import sys\n",
    "import binascii\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "# set working directory\n",
    "os.chdir('C:/_DS710/Temp07')\n",
    "\n",
    "def rmPunctuationStr(s):\n",
    "    rmPunctuation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return s.translate(rmPunctuation_table)\n",
    "\n",
    "\n",
    "def read_input(inputFN):\n",
    "    # exclude appostrophe (right, left, regular), dash\n",
    "    exclusionChars = {chr(8220), chr(8221), chr(34), chr(95)}\n",
    "    tx_str = \"\"\n",
    "    with open(inputFN, 'r') as f_in:\n",
    "        for line in f_in:\n",
    "            if (len(line) > 1):\n",
    "                for ch in line:\n",
    "                    # exclude quotation marks\n",
    "                    if (ch in exclusionChars):\n",
    "                        pass\n",
    "                    # if character is a dash (or hyphen-like), replace with a space\n",
    "                    elif (ch == chr(45)):\n",
    "                        tx_str = tx_str + chr(32)\n",
    "                    else:\n",
    "                        tx_str = tx_str + ch\n",
    "        tx_str = tx_str + chr(32)\n",
    "    return tx_str\n",
    "\n",
    "\n",
    "# splits a text string into a word list by whitespace\n",
    "# input:  a text string containing words delimited by whitespace\n",
    "# output: a list of words\n",
    "def splitTextIntoWordList(txStr):\n",
    "    aWordList = txStr.split(chr(32))\n",
    "\n",
    "    # remove any blank words that were generated due to hypen/space subsitution\n",
    "    bWordList = []\n",
    "    for word in aWordList:\n",
    "        if (word != ''):\n",
    "            bWordList.append(word)\n",
    "    \n",
    "    return bWordList\n",
    "\n",
    "\n",
    "# removes soft carriage returns that may be embedded in a word\n",
    "# - joins incompleted sentences that are separated by soft CRs\n",
    "# - recognize when a new sentence begins after a CR\n",
    "# input:  a list of words that may contain embedded CRs\n",
    "# output: a list of words with the embedded CRs resolved\n",
    "def rmSoftCRs(iList):\n",
    "    wList = []\n",
    "    for word in iList:\n",
    "        # the word does not have a CR\n",
    "        if (word.find(chr(10)) < 0):\n",
    "            wList.append(word)\n",
    "        # the word has an embedded CR\n",
    "        else:\n",
    "            # partition the word into before & after CR\n",
    "            t = word.partition(chr(10))\n",
    "            \n",
    "            # if the before word is blank and the after word is Titled then it is the start of a new sentence\n",
    "            if ((len(t[0]) == 0) and (t[2].istitle())):\n",
    "                wList.append(word)\n",
    "            # the word represents an incomplete sentence, remove the CR & append before & after words\n",
    "            else:\n",
    "                wList.append(t[0])\n",
    "                wList.append(t[2])\n",
    "    return wList\n",
    "\n",
    "# checks to see if an exclusion string is a substring in a word\n",
    "# - needed to use find to handle cases where a CR is preappended\n",
    "#   to the exclusion word\n",
    "# input:  a word/phrase\n",
    "# output: a Boolean (True = exclusion word found)\n",
    "def checkForExclusion(phrase):\n",
    "    returnValue = False\n",
    "    # handle cases were exclusion string is the string in the phrase\n",
    "    exclusionWords = [\"Mr.\", \"Mrs.\", \"Dr.\", \"Fr.\", \"Jr.\", \"St.\"]\n",
    "    if ([elem for elem in exclusionWords if elem == phrase]):\n",
    "        returnValue = True\n",
    "    # handle cases were exclusion string is a substring in the phrase\n",
    "    else:\n",
    "        # check for exclusion substring\n",
    "        if (phrase.find(\"Mr.\") > 0):\n",
    "            returnValue = True\n",
    "        elif (phrase.find(\"Mrs.\") > 0):\n",
    "            returnValue = True\n",
    "        elif (phrase.find(\"Dr.\") > 0):\n",
    "            returnValue = True\n",
    "        elif (phrase.find(\"Fr.\") > 0):\n",
    "            returnValue = True\n",
    "        elif (phrase.find(\"Jr.\") > 0):\n",
    "            returnValue = True\n",
    "        else:\n",
    "            if (phrase.find(\"St.\") > 0):\n",
    "                returnValue = True\n",
    "    return returnValue\n",
    "\n",
    "        \n",
    "# construct new sentences from embedded sentences\n",
    "# - differentiate abbreviations from end of sentences\n",
    "# input:  a list of words\n",
    "# output: a list of words with embedded sentences resolved\n",
    "def resolveEmbeddedSentences(embeddedWordList):\n",
    "    nonEmbeddedWordList = []\n",
    "    i = -1\n",
    "    for word in embeddedWordList:\n",
    "        i = i + 1\n",
    "        # if the word is in the exclusion list, then do not process it as an end of sentence delimiter\n",
    "        if (checkForExclusion(word)):\n",
    "            nonEmbeddedWordList.append(word)\n",
    "        # determine if there is an end of sentence delimiter in the word\n",
    "        else:\n",
    "            # if the word has a period\n",
    "            if (word.find(chr(46)) > 0):\n",
    "                # if there is a CR\n",
    "                if (word.find(chr(10)) > 0):\n",
    "                    # if there is a CR after the period, just append the word\n",
    "                    if ((word.rfind(chr(10))) > word.find(chr(46))):\n",
    "                        nonEmbeddedWordList.append(word)\n",
    "                    # if there is no CR following the period, append a CR to the word & append\n",
    "                    else:\n",
    "                        delimitedWord = word + chr(10)\n",
    "                        nonEmbeddedWordList.append(delimitedWord)\n",
    "                # the word does not have a CR\n",
    "                else:\n",
    "                    delimitedWord = word + chr(10)\n",
    "                    nonEmbeddedWordList.append(delimitedWord)\n",
    "            # the word has an exclamation point\n",
    "            elif (word.find(chr(33)) > 0):\n",
    "                # if there is a CR after the exclamation point, just append the word\n",
    "                if ((word.rfind(chr(10))) > word.find(chr(33))):\n",
    "                    nonEmbeddedWordList.append(word)\n",
    "                # if there is no CR following the period, append a CR to the word & append\n",
    "                else:\n",
    "                    delimitedWord = word + chr(10)\n",
    "                    nonEmbeddedWordList.append(delimitedWord)\n",
    "            # the word has an question mark\n",
    "            elif (word.find(chr(63)) > 0):\n",
    "                # if there is a CR after the question mark, just append the word\n",
    "                if ((word.rfind(chr(10))) > word.find(chr(63))):\n",
    "                    nonEmbeddedWordList.append(word)\n",
    "                # if there is no CR following the period, append a CR to the word & append\n",
    "                else:\n",
    "                    delimitedWord = word + chr(10)\n",
    "                    nonEmbeddedWordList.append(delimitedWord)\n",
    "            # the word was not an embedded sentence, just append the word\n",
    "            else:\n",
    "                nonEmbeddedWordList.append(word)\n",
    "    return nonEmbeddedWordList\n",
    "\n",
    "\n",
    "# split a string of sentences into a lists of sentences by CR\n",
    "# input:  a string of words representing sentences delimited by CRs\n",
    "# output: a list of sentences with each sentence a list of words\n",
    "def convertSentencesToLists(aStringOfSentences):\n",
    "    listsOfSentences = []\n",
    "    aSentence = []\n",
    "    for word in aStringOfSentences:\n",
    "        # the word does not have a CR\n",
    "        if (word.find(chr(10)) < 0):\n",
    "            aSentence.append(word)\n",
    "        # the word has an embedded CR\n",
    "        else:\n",
    "            after_word = word\n",
    "            while (after_word.find(chr(10)) > 0):\n",
    "                # partition the phrase into before & after CR\n",
    "                t = after_word.partition(chr(10))\n",
    "            \n",
    "                # append the before to the current sentence\n",
    "                before_word = t[0]\n",
    "                aSentence.append(before_word)\n",
    "            \n",
    "                # append the current sentence to the document\n",
    "                listsOfSentences.append(aSentence)\n",
    "            \n",
    "                # start a new sentence with the after word\n",
    "                aSentence = []\n",
    "                after_word = t[2]\n",
    "            if (after_word != ''):\n",
    "                aSentence.append(after_word)\n",
    "    listsOfSentences.append(aSentence)\n",
    "    return listsOfSentences\n",
    "\n",
    "# debug:  write to file the list of sentences\n",
    "# input:  output filename, list of sentences\n",
    "# output: output file of words per sentence\n",
    "def writeSentences(outputFN, sList):\n",
    "    file = open(outputFN, 'w')\n",
    "    for sentence in sList:\n",
    "        for word in sentence:\n",
    "            file.write(word)\n",
    "            file.write(\" \")\n",
    "        file.write(chr(10))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "# remove the punctuation characters from the sentenceList\n",
    "# input:  a list of sentence lists with embedded punctuation marks\n",
    "# output: a list of sentence lists with without punctuation marks\n",
    "def rmPunctuationFromSentences(sentList):\n",
    "    cleanedListOfSenences = []\n",
    "    for s in sentList:\n",
    "        cleanedSentence = []\n",
    "        for w in s:\n",
    "            cleanedSentence.append(rmPunctuationStr(w))\n",
    "        cleanedListOfSenences.append(cleanedSentence)\n",
    "    return cleanedListOfSenences\n",
    "\n",
    "\n",
    "# calculate the word length for each word in each sentence\n",
    "# input:  a list of sentence lists which contain words\n",
    "# output: a list of integer lists, each integer represents a the character count of a word in a sentence\n",
    "def sentenceWordLength(cleanedSentenceList):\n",
    "    wordLengthPerSentenceList = []\n",
    "    for sent in cleanedSentenceList:\n",
    "        sentenceWordLen = []\n",
    "        # for each word in a sentence, count the number of characters in the word\n",
    "        for w in sent:\n",
    "            sentenceWordLen.append(len(w))\n",
    "    \n",
    "        # append the word lengths per sentence to the list of sentences\n",
    "        wordLengthPerSentenceList.append(sentenceWordLen)\n",
    "    return wordLengthPerSentenceList\n",
    "\n",
    "\n",
    "# calculate the sum value of the integers in a list\n",
    "# input:  a list of integers\n",
    "# output: an integer representing the sum of the integers in a list\n",
    "def sumIntegerList(integerList):\n",
    "    sumValue = 0\n",
    "    for i in integerList:\n",
    "        sumValue = sumValue + i\n",
    "    return sumValue\n",
    "\n",
    "\n",
    "# calculated sentence statistics\n",
    "# for each sentence:\n",
    "# - count the number of words\n",
    "# - calculate the sum of the length of the words\n",
    "# - calculate the mean lenght of the words\n",
    "# input:  a list of integer lists, each integer represents a the character count of a word in a sentence\n",
    "# output: a list of integer lists, each list represents the total word length, the word count, and the mean word length\n",
    "def calculateSentenceStats(intLists):\n",
    "    sentenceStatList = []\n",
    "    for iSent in intLists:\n",
    "        # initialize statistic variables\n",
    "        sentenceStat = []\n",
    "        totalCharCount = 0\n",
    "        wordCount = 0\n",
    "        meanCharCount = 0\n",
    "        \n",
    "        # calculate statistic variables\n",
    "        totalCharCount = sumIntegerList(iSent)\n",
    "        wordCount = len(iSent)\n",
    "        if (wordCount > 0):\n",
    "            meanCharCount = totalCharCount/wordCount\n",
    "        \n",
    "        # create a list for the sentence's statistics\n",
    "        sentenceStat.append(totalCharCount)\n",
    "        sentenceStat.append(wordCount)\n",
    "        sentenceStat.append(meanCharCount)\n",
    "        \n",
    "        # append the sentence's statistics list to the list of sentence statistics\n",
    "        sentenceStatList.append(sentenceStat)\n",
    "    return sentenceStatList\n",
    "\n",
    "    \n",
    "# create a dataframe to hold the sentence statistics\n",
    "# input:  list of sentence statistics: the total word length, the word count, and the mean word length\n",
    "#         list of sentences with punctuation removed\n",
    "# output: the dataframe\n",
    "def createDF(sentStatList, listOfCleanedSents):\n",
    "    # create a blank dataframe\n",
    "    aDF = pd.DataFrame()\n",
    "    \n",
    "    # create a series for the total word length values\n",
    "    totalWordLengthList = []\n",
    "    for s in sentStatList:\n",
    "        totalWordLengthList.append(s[0])\n",
    "    aDF['totalWordLength'] = totalWordLengthList\n",
    "    \n",
    "    # create a series for the word count values\n",
    "    wordCountList = []\n",
    "    for s in sentStatList:\n",
    "        wordCountList.append(s[1])\n",
    "    aDF['wordCount'] = wordCountList\n",
    "    \n",
    "    # create a series for the mean word length values\n",
    "    meanWordLengthList = []\n",
    "    for s in sentStatList:\n",
    "        meanWordLengthList.append(s[2])\n",
    "    aDF['meanWordLength'] = meanWordLengthList\n",
    "    \n",
    "    # create a series for the cleaned sentences\n",
    "    cleanSentList = []\n",
    "    for cSent in listOfCleanedSents:\n",
    "        cleanSentList.append(cSent)\n",
    "    aDF['cleanSentenceList'] = cleanSentList\n",
    "    \n",
    "    return(aDF)\n",
    "\n",
    "\n",
    "def exportSentenceStatistics(csvFN, bDF):\n",
    "    bDF.to_csv(csvFN, sep=',', encoding='utf-8', quotechar='\"', na_rep='', index=False, index_label=False, \\\n",
    "        columns = ['totalWordLength', 'wordCount', 'meanWordLength', 'cleanSentenceList'], \\\n",
    "        header  = ['totalWordLength', 'wordCount', 'meanWordLength', 'cleanSentenceList'])\n",
    "\n",
    "\n",
    "# main routine\n",
    "#def main():\n",
    "# set the input & output file name\n",
    "inputFileName  = 'Pride.txt'\n",
    "outputFileName = 'Pride_Sentences.txt'\n",
    "csvFileName    = 'Pride_Sentence_Stats.csv'\n",
    "\n",
    "# read the input text character by character\n",
    "textStr = read_input(inputFileName)\n",
    "\n",
    "# create a word list from the text that was read\n",
    "wordList = splitTextIntoWordList(textStr)\n",
    "\n",
    "# remove the soft carriage returns and join the fragmented sentences\n",
    "removedSoftCrWordList = rmSoftCRs(wordList)\n",
    "\n",
    "# break apart multiple sentences within a sentence\n",
    "sentenceWordList = resolveEmbeddedSentences(removedSoftCrWordList)\n",
    "\n",
    "# create a list of sentences with each sentence representingh a list of words\n",
    "sentenceList = convertSentencesToLists(sentenceWordList)\n",
    "\n",
    "# remove the punctuation marks from the list of sentences\n",
    "listOfCleanedSentences = rmPunctuationFromSentences(sentenceList)\n",
    "\n",
    "# count the number of characters per word in each sentence\n",
    "characterWordCountSentenceList = sentenceWordLength(listOfCleanedSentences)\n",
    "\n",
    "# calculate the statistics for a sentence\n",
    "sentenceStatisticsList = calculateSentenceStats(characterWordCountSentenceList)\n",
    "\n",
    "# create a panda containing sentence statistics: the total word length, the word count, and the mean word length\n",
    "df = createDF(sentenceStatisticsList, listOfCleanedSentences)\n",
    "\n",
    "# export the dataframe into a .csv file\n",
    "exportSentenceStatistics(csvFileName, df)\n",
    "\n",
    "# list the top rows of the dataframe\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 Introduction.  Counting the Letter _e_.\n",
    "\n",
    "Here we will be counting e's in text files, capitalized and uncapitalized, and accented and unaccented.\n",
    "\n",
    "* Your code in 2(b) should include a function called ```count_letter_e()``` which takes a string representing a filename, such as ```pg1342.txt```, as input, and returns the number of _e_'s as output.  Your function should include two optional arguments, ```ignore_accents``` and ```ignore_case```.  When ```ignore_accents = True```, your function should count accented characters such as _é_, _ê_, and _è_ as _e_.  When ```ignore_case=True```, your function should treat uppercase and lowercase _e_ as the same letter.\n",
    "* Your code should also include a function called ```count_letters()``` which takes a string representing a filename and returns the number of letters in the file.  This function should not count spaces or punctuation.\n",
    "* Create other functions as necessary to organize your work.\n",
    "* Include comments which explain the purpose and arguments of each function you create.\n",
    "* The files are encoded as utf-8. Unrecognized character error messages can likely be fixed by specifying the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2(a).  Design a Test Suite.\n",
    "\n",
    "Design a test suite (which will be in this case a set of input text) of at least four sentences that will allow you to quickly verify that all four optional argument possibilities are implemented correctly. Make sure that your test suite contains at least one of each of the 8 possible e's (e, é, ê, è, E, É, Ê, È).\n",
    "\n",
    "Save your test suite as a text file for use in your ```count_letter_e()``` function, and also include its contents in a markdown cell below. Also in the markdown cell, for one of the sentences in your test suite (specify which one), count each type of e by hand and report what the output should be for the four possible combinations of true and false for ```ignore_case``` and ```ignore_accents```.\n",
    "\n",
    "*Note that you can complete this portion before you have written a single line of code for your function ```count_letter_e()```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "me conta un jour que => (e, é, ê, è, E, É, Ê, È) = (2,0,0,0,0,0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Suite = 'après tête,général;APRÈS>TÊTE:GÉNÉRAL'\n",
    "------------\n",
    "inFn, ignore_case, ignore_accents                     ( e,é,ê,è, E,É,Ê,È)\n",
    "Test_00_T_T = après tête,général;APRÈS>TÊTE:GÉNÉRAL = (10,0,0,0, 0,0,0,0)\n",
    "Test_00_T_F = après tête,général;APRÈS>TÊTE:GÉNÉRAL = ( 2,4,2,2, 0,0,0,0)\n",
    "Test_00_F_T = après tête,général;APRÈS>TÊTE:GÉNÉRAL = ( 5,0,0,0, 5,0,0,0)\n",
    "Test_00_F_F = après tête,général;APRÈS>TÊTE:GÉNÉRAL = ( 1,2,1,1, 1,2,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2(b). Create and Test Your Code.\n",
    "\n",
    "Create the functions described in Problem 2 Introduction, and apply them to your test suite from 2(a).  Do *not* use Python packages or code directly copied from online resources.  Write your own functions from first principles.\n",
    "\n",
    "Print the results of applying the four combinations of optional arguments of your ```count_letter_e()``` function to your test suite. Verify that the output is correct. (If it isn't modify your code until your function works correctly on your test suite.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIT TESTS\n",
      "----------\n",
      "letter count in 'pride.txt' =  536408\n",
      "digit  count in 'pride.txt'  =  121\n",
      "\n",
      "letter count in l'enlevement.txt =  8277\n",
      "digit  count in l'enlevement.txt =  1\n",
      "\n",
      "assignment7_test_00.txt : ' après tête,général;APRÈS>TÊTE:GÉNÉRAL : Suspected Encoding =  utf-8 ' : ignore_case = True  : ignore_accents = True  : result = (10,0,0,0, 0,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "assignment7_test_00.txt : ' après tête,général;APRÈS>TÊTE:GÉNÉRAL : Suspected Encoding =  utf-8 ' : ignore_case = True  : ignore_accents = False  : result = (2,4,2,2, 0,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "assignment7_test_00.txt : ' après tête,général;APRÈS>TÊTE:GÉNÉRAL : Suspected Encoding =  utf-8 ' : ignore_case = False  : ignore_accents = True  : result = (5,0,0,0, 5,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "assignment7_test_00.txt : ' après tête,général;APRÈS>TÊTE:GÉNÉRAL : Suspected Encoding =  utf-8 ' : ignore_case = False  : ignore_accents = False  : result = (1,2,1,1, 1,2,1,1)  = (e,é,ê,è, E,É,Ê,È)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# import libraries\n",
    "import os\n",
    "import string\n",
    "\n",
    "# set working directory\n",
    "os.chdir('C:/_DS710/Temp07')\n",
    "\n",
    "# define a function to remove the standard punctuation marks from a string\n",
    "# note: a space is not a punctuation mark\n",
    "# input:  a string with punctuation marks\n",
    "# output: a string with punctuation marks removed\n",
    "def rmPunctuationString(s):\n",
    "    rmPunctuation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    processed_String =  s.translate(rmPunctuation_table)\n",
    "    return processed_String\n",
    "\n",
    "\n",
    "# reads an input file of text and stores into an output file a string of characters that exclude spaces, carriage returns\n",
    "# input:  a name of a file that contains characters to be read\n",
    "# output: an output file a string of characters that exclude spaces, carriage returns, and non-printable characters\n",
    "# note: detect encoding of input file via command line chardetect <iFN>\n",
    "def readWriteText(inputTX, inEncode, outputTX):\n",
    "    f2 = open(outputTX, 'w', encoding=\"utf-8\", errors=\"ignore\")\n",
    "    with open(inputTX, 'r', encoding=inEncode, errors=\"ignore\") as f1:\n",
    "        # itterate over the lines in the input text\n",
    "        for iLine1 in iter(f1.readline, \"\"):\n",
    "            # remove the punctuation marks\n",
    "            pLine1 = rmPunctuationString(iLine1)\n",
    "            \n",
    "            # process each processed line of input\n",
    "            if (len(pLine1) > 1):\n",
    "                # process each character in the processed line\n",
    "                for ch1 in pLine1:\n",
    "                    # if the character read is a space or a carriage return, then skip it\n",
    "                    if ((ch1 == chr(32)) or (ch1 == chr(10))):\n",
    "                        pass\n",
    "                    # write the character to the output file\n",
    "                    else:\n",
    "                      f2.write(ch1)\n",
    "    # close all files\n",
    "    f2.close()\n",
    "    f1.close()\n",
    "\n",
    "\n",
    "# count the number of letters (i.e., non-digits [0..9] in a input file; exclude whitespaces, punctuation marks, digits\n",
    "# input:  a name of a file that contains characters to be counted\n",
    "# output: a integer representing the number of letters (non-digit) characters in the file\n",
    "def count_letters(inFN):\n",
    "    # exclude carriage return, space, and digit characters\n",
    "    exclusionChars = {chr(10), chr(32), chr(48), chr(49), chr(50), chr(51), chr(52), chr(52), chr(53), chr(54), chr(55), chr(56), chr(57)}\n",
    "    \n",
    "    # initialize the counter\n",
    "    numberOfLettersInFile = 0\n",
    "    \n",
    "    # process the input file    \n",
    "    with open(inFN, 'r', encoding='utf-8', errors=\"ignore\") as f_in:\n",
    "        for iLine2 in f_in:\n",
    "            if (len(iLine2) > 1):\n",
    "                # remove the punctuation marks\n",
    "                pLine2 = rmPunctuationString(iLine2)\n",
    "                \n",
    "                # count the number of characters in the processed line, exclude digit characters\n",
    "                for ch2 in pLine2:\n",
    "                    # exclude digit characters\n",
    "                    if (ch2 in exclusionChars):\n",
    "                        pass\n",
    "                    else:\n",
    "                        numberOfLettersInFile = numberOfLettersInFile + 1\n",
    "    # return the number of digits found in the input file\n",
    "    return numberOfLettersInFile\n",
    "\n",
    "\n",
    "# count the variants of the letter e in a input file, exclude whitespaces, punctuation marks\n",
    "# input:  a name ofa file that contains characters to be counted, \n",
    "#         the suspected encoding of the input file\n",
    "#         a boolean flag on whether upper/lower case is to be ignored\n",
    "#         a boolean flag on whether accent variations is to be ignored\n",
    "# assumptions: ignore case means that all upper case e variant letters will be added to the lower case letter variant\n",
    "# output: a integer representing the number of variants of the letter e in the form of a tuple constructed as:\n",
    "#         (lower_e_normal, lower_e_acute, lower_e_circumflex, lower_e_grave, \n",
    "#          upper_e_normal, upper_e_acute, upper_e_circumflex, upper_e_grave)\n",
    "def count_letter_e(inFN, inEncoding, ignore_case, ignore_accents):\n",
    "    # define the filename for temporary output\n",
    "    outFN = 'temp.out'\n",
    "    \n",
    "    # initialize count variables for reporting\n",
    "    lower_e_normal     = 0\n",
    "    lower_e_acute      = 0\n",
    "    lower_e_circumflex = 0\n",
    "    lower_e_grave      = 0\n",
    "    upper_e_normal     = 0\n",
    "    upper_e_acute      = 0\n",
    "    upper_e_circumflex = 0\n",
    "    upper_e_grave      = 0\n",
    "\n",
    "    # read all the characters in the input filename and store the characters in a temporary file\n",
    "    # exclude spaces, carriage returns, and non-printable characters\n",
    "    # convert the suspected encoding to utf-8\n",
    "    readWriteText(inFN, inEncoding, outFN)\n",
    "    \n",
    "    # count the occurance of the variants of the letter e\n",
    "    f = open(outFN, 'r', encoding='utf-8', errors=\"ignore\")\n",
    "    while True:\n",
    "        aCh = f.read(1)\n",
    "        if (not aCh):\n",
    "            break\n",
    "        else:\n",
    "            if (aCh == chr(101)):\n",
    "                lower_e_normal = lower_e_normal + 1\n",
    "            elif (aCh == chr(233)):\n",
    "                lower_e_acute = lower_e_acute + 1\n",
    "            elif (aCh == chr(234)):\n",
    "                lower_e_circumflex = lower_e_circumflex + 1\n",
    "            elif (aCh == chr(232)):\n",
    "                lower_e_grave = lower_e_grave + 1\n",
    "            elif (aCh == chr(69)):\n",
    "                upper_e_normal = upper_e_normal + 1\n",
    "            elif (aCh == chr(201)):\n",
    "                upper_e_acute = upper_e_acute + 1\n",
    "            elif (aCh == chr(202)):\n",
    "                upper_e_circumflex = upper_e_circumflex + 1\n",
    "            elif (aCh == chr(200)):\n",
    "                upper_e_grave = upper_e_grave + 1\n",
    "            else:\n",
    "                pass\n",
    "    # close temporary file\n",
    "    f.close\n",
    "    \n",
    "    # process input flags\n",
    "    if ((ignore_case == True) and (ignore_accents == True)):\n",
    "        lower_e_normal = lower_e_normal + lower_e_acute + lower_e_circumflex + lower_e_grave + \\\n",
    "                         upper_e_normal + upper_e_acute + upper_e_circumflex + upper_e_grave\n",
    "        lower_e_acute      = 0\n",
    "        lower_e_circumflex = 0\n",
    "        lower_e_grave      = 0\n",
    "        upper_e_normal     = 0\n",
    "        upper_e_acute      = 0\n",
    "        upper_e_circumflex = 0\n",
    "        upper_e_grave      = 0\n",
    "    elif ((ignore_case == True) and (ignore_accents == False)):\n",
    "        lower_e_normal     = lower_e_normal     + upper_e_normal\n",
    "        lower_e_acute      = lower_e_acute      + upper_e_acute\n",
    "        lower_e_circumflex = lower_e_circumflex + upper_e_circumflex\n",
    "        lower_e_grave      = lower_e_grave      + upper_e_grave\n",
    "        upper_e_normal     = 0\n",
    "        upper_e_acute      = 0\n",
    "        upper_e_circumflex = 0\n",
    "        upper_e_grave      = 0\n",
    "    else:\n",
    "        if ((ignore_case == False) and (ignore_accents == True)):\n",
    "            lower_e_normal     = lower_e_normal + lower_e_acute + lower_e_circumflex + lower_e_grave\n",
    "            upper_e_normal     = upper_e_normal + upper_e_acute + upper_e_circumflex + upper_e_grave\n",
    "            lower_e_acute      = 0\n",
    "            lower_e_circumflex = 0\n",
    "            lower_e_grave      = 0\n",
    "            upper_e_acute      = 0\n",
    "            upper_e_circumflex = 0\n",
    "            upper_e_grave      = 0\n",
    "    \n",
    "    # construct ouput\n",
    "    lower_e_normal_str     = str(lower_e_normal)\n",
    "    lower_e_acute_str      = str(lower_e_acute)\n",
    "    lower_e_circumflex_str = str(lower_e_circumflex)\n",
    "    lower_e_grave_str      = str(lower_e_grave)\n",
    "    upper_e_normal_str     = str(upper_e_normal)\n",
    "    upper_e_acute_str      = str(upper_e_acute)\n",
    "    upper_e_circumflex_str = str(upper_e_circumflex)\n",
    "    upper_e_grave_str      = str(upper_e_grave)\n",
    "\n",
    "    retValue = \"(\" + lower_e_normal_str + \",\" + lower_e_acute_str + \",\" + lower_e_circumflex_str + \",\" + lower_e_grave_str + \", \" + \\\n",
    "                     upper_e_normal_str + \",\" + upper_e_acute_str + \",\" + upper_e_circumflex_str + \",\" + upper_e_grave_str + \")\"    \n",
    "    # return output\n",
    "    return retValue\n",
    "\n",
    "\n",
    "# ---debug ------------------------------------------------------------\n",
    "# count the number of digits (0..9) in a input file, exclude whitespaces, exlcude punctuation marks\n",
    "# input:  a name ofa file that contains characters to be counted\n",
    "# output: a integer representing the number of digit characters in the file\n",
    "def count_digits(inFN):\n",
    "    # only consider digit characters\n",
    "    inclusionChars = {chr(48), chr(49), chr(50), chr(51), chr(52), chr(52), chr(53), chr(54), chr(55), chr(56), chr(57)}\n",
    "    \n",
    "    # initialize the counter\n",
    "    numberOfDigitsInFile = 0\n",
    "    \n",
    "    # process the input file    \n",
    "    with open(inFN, 'r') as f_in:\n",
    "        for line in f_in:\n",
    "            if (len(line) > 1):\n",
    "                for ch in line:\n",
    "                    # only include digit characters\n",
    "                    if (ch in inclusionChars):\n",
    "                        numberOfDigitsInFile = numberOfDigitsInFile + 1\n",
    "    # return the number of digits found in the input file\n",
    "    return numberOfDigitsInFile\n",
    "\n",
    "\n",
    "# write test output\n",
    "# input:  iFN, iStr, ignore_case, ignore_accents\n",
    "# output: formatted results string\n",
    "def writeTestResult(iFN, inEncodeSuspect, iStr, ignore_case, ignore_accents):\n",
    "    print(iFN, \\\n",
    "    \": '\", iStr, \n",
    "    \": Suspected Encoding = \", inEncodeSuspect, \\\n",
    "    \"' : ignore_case =\", ignore_case, \\\n",
    "    \" : ignore_accents =\", ignore_accents, \\\n",
    "    \" : result =\", count_letter_e(iFN, inEncodeSuspect, ignore_case, ignore_accents), \\\n",
    "    \" = (e,é,ê,è, E,É,Ê,È)\")\n",
    "\n",
    "    \n",
    "# ---test -------------------------------------------------------------\n",
    "# unit tests\n",
    "print(\"UNIT TESTS\")\n",
    "print(\"----------\")\n",
    "\n",
    "print(\"letter count in 'pride.txt' = \", count_letters('pride.txt'))\n",
    "print(\"digit  count in 'pride.txt'  = \", count_digits('pride.txt'))\n",
    "print(\"\")\n",
    "\n",
    "print(\"letter count in l'enlevement.txt = \", count_letters(\"l'enlevement.txt\"))\n",
    "print(\"digit  count in l'enlevement.txt = \", count_digits(\"l'enlevement.txt\"))\n",
    "print(\"\")\n",
    "\n",
    "writeTestResult('assignment7_test_00.txt', \"utf-8\", \"après tête,général;APRÈS>TÊTE:GÉNÉRAL\", True,  True)\n",
    "writeTestResult('assignment7_test_00.txt', \"utf-8\", \"après tête,général;APRÈS>TÊTE:GÉNÉRAL\", True,  False)\n",
    "writeTestResult('assignment7_test_00.txt', \"utf-8\", \"après tête,général;APRÈS>TÊTE:GÉNÉRAL\", False, True)\n",
    "writeTestResult('assignment7_test_00.txt', \"utf-8\", \"après tête,général;APRÈS>TÊTE:GÉNÉRAL\", False, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2(c). Apply Your Code.\n",
    "\n",
    "Apply your code from 2(b) to the two provided .txt files for _Pride and Prejudice_  and _L'Enlèvement de la redoute_. For each file print the output of all four combinations of arguments to your count_letter_e function as well as the output of your count_letters function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pride.txt : '  : Suspected Encoding =  utf-8 ' : ignore_case = True  : ignore_accents = True  : result = (69372,0,0,0, 0,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "Pride.txt : '  : Suspected Encoding =  utf-8 ' : ignore_case = True  : ignore_accents = False  : result = (69372,0,0,0, 0,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "Pride.txt : '  : Suspected Encoding =  utf-8 ' : ignore_case = False  : ignore_accents = True  : result = (68641,0,0,0, 731,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "Pride.txt : '  : Suspected Encoding =  utf-8 ' : ignore_case = False  : ignore_accents = False  : result = (68641,0,0,0, 731,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "\n",
      "l'enlevement.txt : '  : Suspected Encoding =  Windows-1252 ' : ignore_case = True  : ignore_accents = True  : result = (1486,0,0,0, 0,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "l'enlevement.txt : '  : Suspected Encoding =  Windows-1252 ' : ignore_case = True  : ignore_accents = False  : result = (1289,151,8,38, 0,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "l'enlevement.txt : '  : Suspected Encoding =  Windows-1252 ' : ignore_case = False  : ignore_accents = True  : result = (1469,0,0,0, 17,0,0,0)  = (e,é,ê,è, E,É,Ê,È)\n",
      "l'enlevement.txt : '  : Suspected Encoding =  Windows-1252 ' : ignore_case = False  : ignore_accents = False  : result = (1273,151,8,37, 16,0,0,1)  = (e,é,ê,è, E,É,Ê,È)\n"
     ]
    }
   ],
   "source": [
    "# Problem 2b: Apply Your Code\n",
    "# ---------------------------------------------------------------------\n",
    "writeTestResult(\"Pride.txt\", \"utf-8\", '', True,  True)\n",
    "writeTestResult(\"Pride.txt\", \"utf-8\", '', True,  False)\n",
    "writeTestResult(\"Pride.txt\", \"utf-8\", '', False, True)\n",
    "writeTestResult(\"Pride.txt\", \"utf-8\", '', False, False)\n",
    "print(\"\")\n",
    "\n",
    "writeTestResult(\"l'enlevement.txt\", \"Windows-1252\", '', True,  True)\n",
    "writeTestResult(\"l'enlevement.txt\", \"Windows-1252\", '', True,  False)\n",
    "writeTestResult(\"l'enlevement.txt\", \"Windows-1252\", '', False, True)\n",
    "writeTestResult(\"l'enlevement.txt\", \"Windows-1252\", '', False, False)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
